{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN4qh/qKXh4axkWEJ742brp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NicolaGabriele/AgentMinorityGame/blob/master/ProgettoDeepLearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8qVmn0NluI3",
        "outputId": "c3932cb3-9c3c-47b2-efdf-22769e150cbd"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm"
      ],
      "metadata": {
        "id": "dW-CZdpb_BPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awWHkUZ2-BrY",
        "outputId": "ec7aa566-5ac7-4dff-b58e-0c566c80af3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu is selected !\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from torchsummary import summary\n",
        "from sklearn.metrics import f1_score\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models as resnet_model\n",
        "import torchvision\n",
        "import os\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "print(str(device) + ' is selected !')\n",
        "\n",
        "IMAGES_DIR = '/content/drive/MyDrive/machinedeeplearning/BUS_UC/All/images'\n",
        "LABELS_DIR = '/content/drive/MyDrive/machinedeeplearning/BUS_UC/All/masks'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#***Dataset Loading***"
      ],
      "metadata": {
        "id": "RmdXcmqwlFSu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, img_dir, lab_dir):\n",
        "    super(Dataset, self).__init__()\n",
        "    self.img_dir = img_dir\n",
        "    self.lab_dir = lab_dir\n",
        "    self.img_names = os.listdir(img_dir)\n",
        "    self.lab_names = os.listdir(lab_dir)\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    img_name = os.path.join(self.img_dir,self.img_names[idx])\n",
        "    mask_name = os.path.join(self.lab_dir, self.lab_names[idx])\n",
        "    image = torchvision.io.read_image(img_name)\n",
        "    mask = torchvision.io.read_image(mask_name)\n",
        "    return (image,mask)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(os.listdir(self.img_dir))"
      ],
      "metadata": {
        "id": "S7axHm52lJa0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls '/content/drive/MyDrive/machinedeeplearning/BUS_UC/All/images'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ig4peNzsn6cV",
        "outputId": "5ae59f9b-e4ad-452a-d89d-9e4127929ec5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "00105.png  00174.png  00266.png  00370.png  00455.png  0110.png  0170.png  0270.png  0341.png\n",
            "00107.png  00177.png  0026.png\t 00372.png  00459.png  0116.png  0171.png  0274.png  0342.png\n",
            "00108.png  00179.png  00272.png  00375.png  00460.png  0117.png  0175.png  0276.png  0343.png\n",
            "00110.png  0017.png   00279.png  00380.png  00466.png  0123.png  0176.png  0277.png  0349.png\n",
            "00112.png  00181.png  00280.png  00381.png  00469.png  0124.png  0184.png  0279.png  034.png\n",
            "00116.png  00190.png  00281.png  00382.png  00471.png  0126.png  0195.png  0280.png  0350.png\n",
            "00117.png  00191.png  00283.png  00383.png  00474.png  012.png\t 01.png    0282.png  0354.png\n",
            "00119.png  00192.png  00287.png  00385.png  00476.png  0130.png  0200.png  0285.png  0358.png\n",
            "0011.png   00196.png  0028.png\t 0038.png   00479.png  0131.png  0201.png  0288.png  0359.png\n",
            "00122.png  00199.png  00295.png  00392.png  00481.png  0134.png  0202.png  028.png   0361.png\n",
            "00125.png  00204.png  00303.png  00396.png  00485.png  0135.png  0205.png  0297.png  039.png\n",
            "00129.png  00206.png  00305.png  00401.png  0049.png   0138.png  0207.png  0299.png  049.png\n",
            "0012.png   00207.png  00307.png  00406.png  0052.png   0139.png  0209.png  02.png    052.png\n",
            "00131.png  00210.png  00308.png  0040.png   0053.png   0141.png  0212.png  0301.png  053.png\n",
            "00134.png  00211.png  00315.png  00419.png  0054.png   0145.png  0225.png  0307.png  054.png\n",
            "00136.png  00212.png  00324.png  0041.png   005.png    0146.png  0226.png  0309.png  056.png\n",
            "00139.png  00217.png  00335.png  00421.png  0063.png   0148.png  0230.png  030.png   060.png\n",
            "00141.png  00224.png  00343.png  00424.png  0064.png   0152.png  0233.png  0312.png  063.png\n",
            "00145.png  00225.png  00349.png  00426.png  0070.png   0154.png  0244.png  0316.png  068.png\n",
            "00147.png  00229.png  00353.png  00428.png  0072.png   0159.png  0245.png  0318.png  071.png\n",
            "00149.png  00235.png  00354.png  00431.png  0074.png   0160.png  0252.png  0325.png  072.png\n",
            "00156.png  00237.png  00355.png  00434.png  0075.png   0162.png  0255.png  0327.png  076.png\n",
            "0015.png   0023.png   00359.png  00440.png  0086.png   0163.png  0262.png  0329.png  078.png\n",
            "00162.png  00240.png  00361.png  00444.png  0092.png   0164.png  0264.png  032.png   082.png\n",
            "00164.png  00241.png  00364.png  00445.png  0093.png   0165.png  0266.png  0333.png  087.png\n",
            "00168.png  00247.png  00367.png  0044.png   0101.png   0166.png  0267.png  0334.png  088.png\n",
            "00169.png  00252.png  00368.png  00453.png  0102.png   0167.png  0268.png  0335.png  093.png\n",
            "00171.png  00256.png  0036.png\t 00454.png  0106.png   0168.png  026.png   0340.png  099.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#***MET-NET***"
      ],
      "metadata": {
        "id": "e6uPGnVVk8mM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderBottleneckLayer(nn.Module):\n",
        "    def __init__(self, in_channels, n_filters, use_transpose=True):\n",
        "        super(DecoderBottleneckLayer, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, in_channels // 4, 1)\n",
        "        self.norm1 = nn.BatchNorm2d(in_channels // 4)\n",
        "        self.relu1 = nn.LeakyReLU()\n",
        "\n",
        "        if use_transpose:\n",
        "            self.up = nn.Sequential(\n",
        "                nn.ConvTranspose2d(\n",
        "                    in_channels // 4, in_channels // 4, 3, stride=2, padding=1, output_padding=1\n",
        "                ),\n",
        "                nn.BatchNorm2d(in_channels // 4),\n",
        "                nn.LeakyReLU()\n",
        "            )\n",
        "        else:\n",
        "            self.up = nn.Upsample(scale_factor=2, align_corners=True, mode=\"bilinear\")\n",
        "\n",
        "        self.conv3 = nn.Conv2d(in_channels // 4, n_filters, 1)\n",
        "        self.norm3 = nn.BatchNorm2d(n_filters)\n",
        "        self.relu3 = nn.LeakyReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.norm1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.up(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.norm3(x)\n",
        "        x = self.relu3(x)\n",
        "        return x\n",
        "\n",
        "class FFBlock(nn.Module):\n",
        "    def __init__(self, channels):\n",
        "        super(FFBlock, self).__init__()\n",
        "\n",
        "        self.conv3 = nn.Conv2d(in_channels=channels, out_channels=channels, kernel_size=3, padding=1)\n",
        "        self.conv1 = nn.Conv2d(in_channels=channels, out_channels=channels, kernel_size=1)\n",
        "\n",
        "        self.relu3 = nn.LeakyReLU()\n",
        "        self.relu1 = nn.LeakyReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x3 = self.conv3(x)\n",
        "        x3 = self.relu3(x3)\n",
        "        x1 = self.conv1(x)\n",
        "        x1 = self.relu1(x1)\n",
        "        out = x3 + x1\n",
        "\n",
        "        return out\n",
        "\n",
        "class SEBlock(nn.Module):\n",
        "    def __init__(self, channel, r=16):\n",
        "        super(SEBlock, self).__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(channel, channel // r, bias=False),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(channel // r, channel, bias=False),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, _, _ = x.size()\n",
        "        ## Squeeze operation\n",
        "        y = self.avg_pool(x).view(b, c)\n",
        "        ## Excitation operation\n",
        "        y = self.fc(y).view(b, c, 1, 1)\n",
        "        ## Fusion operation\n",
        "        y = torch.mul(x, y)\n",
        "        return y\n",
        "\n",
        "class PDFBlock(nn.Module):\n",
        "    def __init__(self,in_channels, out_channels_list, kernel_size_list, dilation_list):\n",
        "        super(PDFBlock, self).__init__()\n",
        "        self.conv_num = len(out_channels_list)\n",
        "        assert(self.conv_num == 4)\n",
        "        assert(self.conv_num == len(kernel_size_list) and self.conv_num == len(dilation_list))\n",
        "        pad0 = int((kernel_size_list[0] - 1) / 2 * dilation_list[0])\n",
        "        pad1 = int((kernel_size_list[1] - 1) / 2 * dilation_list[1])\n",
        "        pad2 = int((kernel_size_list[2] - 1) / 2 * dilation_list[2])\n",
        "        pad3 = int((kernel_size_list[3] - 1) / 2 * dilation_list[3])\n",
        "        self.conv_1 = nn.Conv2d(in_channels, out_channels_list[0], kernel_size = kernel_size_list[0], dilation = dilation_list[0], padding = pad0 )\n",
        "        self.conv_2 = nn.Conv2d(in_channels, out_channels_list[1], kernel_size = kernel_size_list[1], dilation = dilation_list[1], padding = pad1 )\n",
        "        self.conv_3 = nn.Conv2d(in_channels, out_channels_list[2], kernel_size = kernel_size_list[2], dilation = dilation_list[2], padding = pad2 )\n",
        "        self.conv_4 = nn.Conv2d(in_channels, out_channels_list[3], kernel_size = kernel_size_list[3], dilation = dilation_list[3], padding = pad3 )\n",
        "\n",
        "        out_channels  = out_channels_list[0] + out_channels_list[1] + out_channels_list[2] + out_channels_list[3]\n",
        "        self.conv_1x1 = nn.Sequential(\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=1, padding=0),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.LeakyReLU())\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.conv_1(x)\n",
        "        x2 = self.conv_2(x)\n",
        "        x3 = self.conv_3(x)\n",
        "        x4 = self.conv_4(x)\n",
        "\n",
        "        y  = torch.cat([x1, x2, x3, x4], dim=1)\n",
        "        y  = self.conv_1x1(y)\n",
        "        return y\n",
        "\n",
        "class MET_Net(nn.Module):\n",
        "    def __init__(self, n_channels=3, n_classes=1):\n",
        "        super(MET_Net, self).__init__()\n",
        "\n",
        "        transformer = torch.hub.load('facebookresearch/deit:main', 'deit_tiny_distilled_patch16_224', pretrained=True)\n",
        "        resnet = resnet_model.resnet18(pretrained=True)\n",
        "\n",
        "        self.firstconv = resnet.conv1\n",
        "        self.firstbn = resnet.bn1\n",
        "        self.firstrelu = resnet.relu\n",
        "\n",
        "        self.encoder1 = resnet.layer1\n",
        "        self.encoder2 = resnet.layer2\n",
        "        self.encoder3 = resnet.layer3\n",
        "        self.encoder4 = resnet.layer4\n",
        "\n",
        "        self.patch_embed = transformer.patch_embed\n",
        "        self.transformers = nn.ModuleList( [transformer.blocks[i] for i in range(12)] )\n",
        "\n",
        "        self.conv_seq_img = nn.Conv2d(in_channels=192, out_channels=512, kernel_size=1, padding=0)\n",
        "        self.se = SEBlock(channel=1024)\n",
        "        self.conv2d = nn.Conv2d(in_channels=1024, out_channels=512, kernel_size=1, padding=0)\n",
        "\n",
        "        self.FFBlock1 = FFBlock(channels=64)\n",
        "        self.FFBlock2 = FFBlock(channels=128)\n",
        "        self.FFBlock3 = FFBlock(channels=256)\n",
        "\n",
        "        self.FFB1 = nn.ModuleList([self.FFBlock1 for i in range(6)])\n",
        "        self.FFB2 = nn.ModuleList([self.FFBlock2 for i in range(4)])\n",
        "        self.FFB3 = nn.ModuleList([self.FFBlock3 for i in range(2)])\n",
        "\n",
        "        filters = [64, 128, 256, 512]\n",
        "\n",
        "        self.decoder4 = DecoderBottleneckLayer(filters[3], filters[2])\n",
        "        self.decoder3 = DecoderBottleneckLayer(filters[2], filters[1])\n",
        "        self.decoder2 = DecoderBottleneckLayer(filters[1], filters[0])\n",
        "        self.decoder1 = DecoderBottleneckLayer(filters[0], filters[0])\n",
        "\n",
        "        self.final_conv1 = nn.ConvTranspose2d(filters[0], 32, 4, 2, 1)\n",
        "        self.final_relu1 = nn.LeakyReLU()\n",
        "        self.final_conv2 = nn.Conv2d(32, 32, 3, padding=1)\n",
        "        self.final_relu2 = nn.LeakyReLU()\n",
        "        self.final_conv3 = nn.Conv2d(32, n_classes, 3, padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, h, w = x.shape\n",
        "\n",
        "        e0 = self.firstconv(x)\n",
        "        e0 = self.firstbn(e0)\n",
        "        e0 = self.firstrelu(e0)\n",
        "\n",
        "        e1 = self.encoder1(e0)\n",
        "        e2 = self.encoder2(e1)\n",
        "        e3 = self.encoder3(e2)\n",
        "        feature_cnn = self.encoder4(e3)\n",
        "\n",
        "        emb = self.patch_embed(x)\n",
        "        for i in range(12):\n",
        "            emb = self.transformers[i](emb)\n",
        "\n",
        "        feature_tf = emb.permute(0, 2, 1)\n",
        "        feature_tf = feature_tf.view(b, 192, 14, 14)\n",
        "        feature_tf = self.conv_seq_img(feature_tf)\n",
        "\n",
        "        feature_cat = torch.cat((feature_cnn, feature_tf), dim=1)\n",
        "        feature_att = self.se(feature_cat)\n",
        "        feature_out = self.conv2d(feature_att)\n",
        "\n",
        "        for i in range(2):\n",
        "            e3 = self.FFB3[i](e3)\n",
        "        for i in range(4):\n",
        "            e2 = self.FFB2[i](e2)\n",
        "        for i in range(6):\n",
        "            e1 = self.FFB1[i](e1)\n",
        "\n",
        "        d4 = self.decoder4(feature_out) + e3\n",
        "        d3 = self.decoder3(d4) + e2\n",
        "        d2 = self.decoder2(d3) + e1\n",
        "\n",
        "        out1 = self.final_conv1(d2)\n",
        "        out1 = self.final_relu1(out1)\n",
        "\n",
        "        out = self.final_conv2(out1)\n",
        "        out = self.final_relu2(out)\n",
        "        out = self.final_conv3(out)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "nkRyLfiO-Z6p"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MET_Net()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESzgAzWE-eci",
        "outputId": "731cc659-e7d7-4113-8143-28a079fa368b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_deit_main\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "t = torch.randn((1,3,224,224))\n",
        "model(t).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bxpm_bqzsRqC",
        "outputId": "f324c96e-1420-492f-a190-20b275fc679d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 224, 224])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    }
  ]
}